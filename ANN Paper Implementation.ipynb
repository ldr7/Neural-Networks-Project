{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "% matplotlib inline\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "Image rows: 28\n",
      "Image columns: 28\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_features, train_labels), (test_features, test_labels) = mnist.load_data()\n",
    "_, img_rows, img_cols =  train_features.shape\n",
    "num_classes = len(np.unique(train_labels))\n",
    "num_input_nodes = img_rows*img_cols\n",
    "print (\"Number of training samples: %d\"%train_features.shape[0])\n",
    "print (\"Number of test samples: %d\"%test_features.shape[0])\n",
    "print (\"Image rows: %d\"%train_features.shape[1])\n",
    "print (\"Image columns: %d\"%train_features.shape[2])\n",
    "print (\"Number of classes: %d\"%num_classes)\n",
    "extra=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.reshape(train_features.shape[0], 1, img_rows, img_cols).astype('float32')\n",
    "test_features = test_features.reshape(test_features.shape[0], 1, img_rows, img_cols).astype('float32')\n",
    "train_features /= 255\n",
    "test_features /= 255\n",
    "# convert class labels to binary class labels\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "dwt_train_features=pywt.dwt2(train_features,'db38')\n",
    "dwt_test_features=pywt.dwt2(test_features,'db38')\n",
    "cA_train, (cH_train, cV_train, cD_train) = dwt_train_features\n",
    "cA_test, (cH_test, cV_test, cD_test) = dwt_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 51, 51)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(cA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/4\n",
      " - 409s - loss: 1.0596 - acc: 0.6679 - val_loss: 0.2450 - val_acc: 0.9312\n",
      "Epoch 2/4\n",
      " - 407s - loss: 0.2057 - acc: 0.9408 - val_loss: 0.1178 - val_acc: 0.9655\n",
      "Epoch 3/4\n",
      " - 389s - loss: 0.1271 - acc: 0.9615 - val_loss: 0.0873 - val_acc: 0.9746\n",
      "Epoch 4/4\n",
      " - 390s - loss: 0.0978 - acc: 0.9706 - val_loss: 0.0722 - val_acc: 0.9793\n",
      "1594.9407465457916\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Convolution2D(30,(4,4),input_shape=(1,51,51),activation='relu',data_format='channels_first'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.3))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(128,activation='relu'))\n",
    "model5.add(Dense(20,activation='relu'))\n",
    "model5.add(Dense(num_classes,activation='softmax'))\n",
    "model5.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "start = time.time()\n",
    "model5.fit(cA_train, train_labels, batch_size=600, nb_epoch=4, verbose=2, validation_split=0.2)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07040201182570309, 0.9769]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores=model5.evaluate(cA_test,test_labels,verbose=0)\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/4\n",
      " - 386s - loss: 1.4479 - acc: 0.5262 - val_loss: 0.8661 - val_acc: 0.7434\n",
      "Epoch 2/4\n",
      " - 390s - loss: 0.7657 - acc: 0.7579 - val_loss: 0.5919 - val_acc: 0.8187\n",
      "Epoch 3/4\n",
      " - 386s - loss: 0.6063 - acc: 0.8076 - val_loss: 0.5217 - val_acc: 0.8373\n",
      "Epoch 4/4\n",
      " - 409s - loss: 0.5309 - acc: 0.8327 - val_loss: 0.4647 - val_acc: 0.8534\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Convolution2D(30,(4,4),input_shape=(1,51,51),activation='relu',data_format='channels_first'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Dropout(0.3))\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(128,activation='relu'))\n",
    "model6.add(Dense(20,activation='relu'))\n",
    "model6.add(Dense(num_classes,activation='softmax'))\n",
    "model6.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "start = time.time()\n",
    "model6.fit(cH_train, train_labels, batch_size=600, nb_epoch=4, verbose=2, validation_split=0.2)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4575517570257187, 0.8558]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores1=model6.evaluate(cH_test,test_labels,verbose=0)\n",
    "acc_scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/4\n",
      " - 405s - loss: 1.5076 - acc: 0.4824 - val_loss: 0.8406 - val_acc: 0.7245\n",
      "Epoch 2/4\n",
      " - 413s - loss: 0.7588 - acc: 0.7497 - val_loss: 0.5665 - val_acc: 0.8146\n",
      "Epoch 3/4\n",
      " - 408s - loss: 0.5963 - acc: 0.8042 - val_loss: 0.4789 - val_acc: 0.8431\n",
      "Epoch 4/4\n",
      " - 391s - loss: 0.5223 - acc: 0.8298 - val_loss: 0.4380 - val_acc: 0.8553\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Convolution2D(30,(4,4),input_shape=(1,51,51),activation='relu',data_format='channels_first'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Dropout(0.3))\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(128,activation='relu'))\n",
    "model7.add(Dense(20,activation='relu'))\n",
    "model7.add(Dense(num_classes,activation='softmax'))\n",
    "model7.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "start = time.time()\n",
    "model7.fit(cV_train, train_labels, batch_size=600, epochs=4, verbose=2, validation_split=0.2)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.43668596947193145, 0.8589]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores2=model7.evaluate(cV_test,test_labels,verbose=0)\n",
    "acc_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/4\n",
      " - 416s - loss: 1.7498 - acc: 0.4048 - val_loss: 1.1849 - val_acc: 0.6171\n",
      "Epoch 2/4\n",
      " - 413s - loss: 1.0647 - acc: 0.6488 - val_loss: 0.8955 - val_acc: 0.7180\n",
      "Epoch 3/4\n",
      " - 409s - loss: 0.8826 - acc: 0.7122 - val_loss: 0.7587 - val_acc: 0.7543\n",
      "Epoch 4/4\n",
      " - 407s - loss: 0.7735 - acc: 0.7478 - val_loss: 0.6841 - val_acc: 0.7781\n"
     ]
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Convolution2D(30,(4,4),input_shape=(1,51,51),activation='relu',data_format='channels_first'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(0.3))\n",
    "model8.add(Flatten())\n",
    "model8.add(Dense(128,activation='relu'))\n",
    "model8.add(Dense(20,activation='relu'))\n",
    "model8.add(Dense(num_classes,activation='softmax'))\n",
    "model8.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "start = time.time()\n",
    "model8.fit(cD_train, train_labels, batch_size=600, epochs=4, verbose=2, validation_split=0.2)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6815029242992401, 0.7834]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores3=model8.evaluate(cD_test,test_labels,verbose=0)\n",
    "acc_scores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cAtemp_test=cA_test\n",
    "cHtemp_test=cH_test\n",
    "cVtemp_test=cV_test\n",
    "cDtemp_test=cD_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 51, 51)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=cAtemp_test[1]\n",
    "np.shape(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using weighted acc. as metric for predicting test set images.\n",
    "finalans=[]\n",
    "for x in range(10000):\n",
    "    #cAtemp_test = np.expand_dims(cAtemp_test, axis=0)\n",
    "    #cHtemp_test = np.expand_dims(cHtemp_test, axis=0)\n",
    "    #cVtemp_test = np.expand_dims(cVtemp_test, axis=0)\n",
    "    #cDtemp_test = np.expand_dims(cDtemp_test, axis=0)\n",
    "    temp1=cAtemp_test[x,:,:,:]\n",
    "    temp1 = np.expand_dims(temp1, axis=0)\n",
    "    arg1=np.argmax(model5.predict(temp1))\n",
    "    max1=np.max(model5.predict(temp1))\n",
    "    #print(arg1)\n",
    "    temp2=cHtemp_test[x,:,:,:]\n",
    "    temp2 = np.expand_dims(temp2, axis=0)\n",
    "    arg2=np.argmax(model6.predict(temp2))\n",
    "    max2=np.max(model6.predict(temp1))\n",
    "    \n",
    "    temp3=cVtemp_test[x,:,:,:]\n",
    "    temp3 = np.expand_dims(temp3, axis=0)\n",
    "    arg3=np.argmax(model7.predict(temp3))\n",
    "    max3=np.max(model7.predict(temp1))\n",
    "    \n",
    "    temp4=cDtemp_test[x,:,:,:]\n",
    "    temp4 = np.expand_dims(temp4, axis=0)\n",
    "    arg4=np.argmax(model8.predict(temp4))\n",
    "    max4=np.max(model8.predict(temp1))\n",
    "    \n",
    "    ans=np.argmax([acc_scores[1]*max1,acc_scores1[1]*max2,acc_scores2[1]*max3,acc_scores3[1]*max4])\n",
    "    tt=[arg1,arg2,arg3,arg4]\n",
    "    #print(tt[ans])\n",
    "    finalans.append(tt[ans])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7834"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores3[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.86\n"
     ]
    }
   ],
   "source": [
    "accfinal=0\n",
    "for x in range(10000):\n",
    "    if finalans[x]==extra[x]:\n",
    "        accfinal+=1\n",
    "accfinal/=10000\n",
    "print(accfinal*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
