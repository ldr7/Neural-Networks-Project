{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "% matplotlib inline\n",
    "np.random.seed(2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "Image rows: 28\n",
      "Image columns: 28\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_features, train_labels), (test_features, test_labels) = mnist.load_data()\n",
    "_, img_rows, img_cols =  train_features.shape\n",
    "num_classes = len(np.unique(train_labels))\n",
    "num_input_nodes = img_rows*img_cols\n",
    "print (\"Number of training samples: %d\"%train_features.shape[0])\n",
    "print (\"Number of test samples: %d\"%test_features.shape[0])\n",
    "print (\"Image rows: %d\"%train_features.shape[1])\n",
    "print (\"Image columns: %d\"%train_features.shape[2])\n",
    "print (\"Number of classes: %d\"%num_classes)\n",
    "extra=test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.reshape(train_features.shape[0], 1, img_rows, img_cols).astype('float32')\n",
    "test_features = test_features.reshape(test_features.shape[0], 1, img_rows, img_cols).astype('float32')\n",
    "train_features /= 255\n",
    "test_features /= 255\n",
    "# convert class labels to binary class labels\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywt\n",
    "dwt_train_features=pywt.dwt2(train_features,'haar')\n",
    "dwt_test_features=pywt.dwt2(test_features,'haar')\n",
    "cA_train, (cH_train, cV_train, cD_train) = dwt_train_features\n",
    "cA_test, (cH_test, cV_test, cD_test) = dwt_test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 14, 14)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(cA_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      " - 21s - loss: 1.5860 - acc: 0.4609 - val_loss: 0.6641 - val_acc: 0.8274\n",
      "Epoch 2/3\n",
      " - 22s - loss: 0.6418 - acc: 0.8036 - val_loss: 0.2830 - val_acc: 0.9218\n",
      "Epoch 3/3\n",
      " - 21s - loss: 0.3974 - acc: 0.8790 - val_loss: 0.2003 - val_acc: 0.9419\n",
      "64.70462250709534\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Convolution2D(30,(4,4),input_shape=(1, 14, 14),activation='relu',data_format='channels_first'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.3))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(128,activation='relu'))\n",
    "model5.add(Dense(20,activation='relu'))\n",
    "model5.add(Dense(num_classes,activation='softmax'))\n",
    "model5.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "start = time.time()\n",
    "model5.fit(cA_train, train_labels, batch_size=600, nb_epoch=3, verbose=2, validation_split=0.2)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.19965975290238858, 0.9437]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores=model5.evaluate(cA_test,test_labels,verbose=0)\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      " - 20s - loss: 1.8224 - acc: 0.3826 - val_loss: 1.0284 - val_acc: 0.7254\n",
      "Epoch 2/3\n",
      " - 20s - loss: 0.9364 - acc: 0.7140 - val_loss: 0.5659 - val_acc: 0.8422\n",
      "Epoch 3/3\n",
      " - 23s - loss: 0.6622 - acc: 0.7912 - val_loss: 0.4364 - val_acc: 0.8728\n"
     ]
    }
   ],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(Convolution2D(30,(4,4),input_shape=(1, 14, 14),activation='relu',data_format='channels_first'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model6.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model6.add(Dropout(0.3))\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(128,activation='relu'))\n",
    "model6.add(Dense(20,activation='relu'))\n",
    "model6.add(Dense(num_classes,activation='softmax'))\n",
    "model6.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "start = time.time()\n",
    "model6.fit(cH_train, train_labels, batch_size=600, nb_epoch=3, verbose=2, validation_split=0.2)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.43049149243831636, 0.8749]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores1=model6.evaluate(cH_test,test_labels,verbose=0)\n",
    "acc_scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      " - 23s - loss: 1.8026 - acc: 0.3664 - val_loss: 1.0308 - val_acc: 0.6899\n",
      "Epoch 2/3\n",
      " - 23s - loss: 1.0007 - acc: 0.6728 - val_loss: 0.6934 - val_acc: 0.7891\n",
      "Epoch 3/3\n",
      " - 25s - loss: 0.7853 - acc: 0.7442 - val_loss: 0.5525 - val_acc: 0.8329\n"
     ]
    }
   ],
   "source": [
    "model7 = Sequential()\n",
    "model7.add(Convolution2D(30,(4,4),input_shape=(1, 14, 14),activation='relu',data_format='channels_first'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model7.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model7.add(Dropout(0.3))\n",
    "model7.add(Flatten())\n",
    "model7.add(Dense(128,activation='relu'))\n",
    "model7.add(Dense(20,activation='relu'))\n",
    "model7.add(Dense(num_classes,activation='softmax'))\n",
    "model7.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "start = time.time()\n",
    "model7.fit(cV_train, train_labels, batch_size=600, epochs=3, verbose=2, validation_split=0.2)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5437011818885803, 0.8328]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores2=model7.evaluate(cV_test,test_labels,verbose=0)\n",
    "acc_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      " - 23s - loss: 2.0712 - acc: 0.2741 - val_loss: 1.6213 - val_acc: 0.4924\n",
      "Epoch 2/3\n",
      " - 23s - loss: 1.5629 - acc: 0.4759 - val_loss: 1.3506 - val_acc: 0.5601\n",
      "Epoch 3/3\n",
      " - 23s - loss: 1.3857 - acc: 0.5370 - val_loss: 1.1874 - val_acc: 0.6245\n"
     ]
    }
   ],
   "source": [
    "model8 = Sequential()\n",
    "model8.add(Convolution2D(30,(4,4),input_shape=(1, 14, 14),activation='relu',data_format='channels_first'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model8.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model8.add(Dropout(0.3))\n",
    "model8.add(Flatten())\n",
    "model8.add(Dense(128,activation='relu'))\n",
    "model8.add(Dense(20,activation='relu'))\n",
    "model8.add(Dense(num_classes,activation='softmax'))\n",
    "model8.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "start = time.time()\n",
    "model8.fit(cD_train, train_labels, batch_size=600, epochs=3, verbose=2, validation_split=0.2)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1916378648757935, 0.622]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores3=model8.evaluate(cD_test,test_labels,verbose=0)\n",
    "acc_scores3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cAtemp_test=cA_test\n",
    "cHtemp_test=cH_test\n",
    "cVtemp_test=cV_test\n",
    "cDtemp_test=cD_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14, 14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp=cAtemp_test[1]\n",
    "np.shape(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-b5c9e9113f03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmax4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel8\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mans\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mtt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marg2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marg3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0marg4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'acc' is not defined"
     ]
    }
   ],
   "source": [
    "finalans=[]\n",
    "for x in range(10000):\n",
    "    #cAtemp_test = np.expand_dims(cAtemp_test, axis=0)\n",
    "    #cHtemp_test = np.expand_dims(cHtemp_test, axis=0)\n",
    "    #cVtemp_test = np.expand_dims(cVtemp_test, axis=0)\n",
    "    #cDtemp_test = np.expand_dims(cDtemp_test, axis=0)\n",
    "    temp1=cAtemp_test[x,:,:,:]\n",
    "    temp1 = np.expand_dims(temp1, axis=0)\n",
    "    arg1=np.argmax(model5.predict(temp1))\n",
    "    max1=np.max(model5.predict(temp1))\n",
    "    #print(arg1)\n",
    "    temp2=cHtemp_test[x,:,:,:]\n",
    "    temp2 = np.expand_dims(temp2, axis=0)\n",
    "    arg2=np.argmax(model6.predict(temp2))\n",
    "    max2=np.max(model6.predict(temp1))\n",
    "    \n",
    "    temp3=cVtemp_test[x,:,:,:]\n",
    "    temp3 = np.expand_dims(temp3, axis=0)\n",
    "    arg3=np.argmax(model7.predict(temp3))\n",
    "    max3=np.max(model7.predict(temp1))\n",
    "    \n",
    "    temp4=cDtemp_test[x,:,:,:]\n",
    "    temp4 = np.expand_dims(temp4, axis=0)\n",
    "    arg4=np.argmax(model8.predict(temp4))\n",
    "    max4=np.max(model8.predict(temp1))\n",
    "    \n",
    "    ans=np.argmax([acc*max1,acc1*max2,acc2*max3,acc3*max4])\n",
    "    tt=[arg1,arg2,arg3,arg4]\n",
    "    print(tt[ans])\n",
    "    finalans.append(tt[ans])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accfinal=0\n",
    "for x in range(10000):\n",
    "    if finalans[x]==extra[x]:\n",
    "        accfinal+=1\n",
    "accfinal/=10000\n",
    "print(accfinal*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
