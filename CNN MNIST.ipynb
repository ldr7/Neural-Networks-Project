{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "% matplotlib inline\n",
    "np.random.seed(2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n",
      "Image rows: 28\n",
      "Image columns: 28\n",
      "Number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_features, train_labels), (test_features, test_labels) = mnist.load_data()\n",
    "_, img_rows, img_cols =  train_features.shape\n",
    "num_classes = len(np.unique(train_labels))\n",
    "num_input_nodes = img_rows*img_cols\n",
    "print (\"Number of training samples: %d\"%train_features.shape[0])\n",
    "print (\"Number of test samples: %d\"%test_features.shape[0])\n",
    "print (\"Image rows: %d\"%train_features.shape[1])\n",
    "print (\"Image columns: %d\"%train_features.shape[2])\n",
    "print (\"Number of classes: %d\"%num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_features.reshape(train_features.shape[0], 1, img_rows, img_cols).astype('float32')\n",
    "test_features = test_features.reshape(test_features.shape[0], 1, img_rows, img_cols).astype('float32')\n",
    "train_features /= 255\n",
    "test_features /= 255\n",
    "# convert class labels to binary class labels\n",
    "train_labels = np_utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = np_utils.to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    predicted_class = np.argmax(result, axis=1)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(predicted_class == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/3\n",
      " - 139s - loss: 0.9778 - acc: 0.6846 - val_loss: 0.3519 - val_acc: 0.8987\n",
      "Epoch 2/3\n",
      " - 141s - loss: 0.3558 - acc: 0.8915 - val_loss: 0.2076 - val_acc: 0.9397\n",
      "Epoch 3/3\n",
      " - 140s - loss: 0.2184 - acc: 0.9342 - val_loss: 0.1273 - val_acc: 0.9619\n"
     ]
    }
   ],
   "source": [
    "model5 = Sequential()\n",
    "model5.add(Convolution2D(30,(4,4),input_shape=(1, 28, 28),activation='relu',data_format='channels_first'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Convolution2D(10,(2,2),activation='relu',data_format='channels_first'))\n",
    "model5.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model5.add(Dropout(0.3))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(128,activation='relu'))\n",
    "model5.add(Dense(20,activation='relu'))\n",
    "model5.add(Dense(num_classes,activation='softmax'))\n",
    "model5.compile(optimizer='adam', metrics=['accuracy'], loss='categorical_crossentropy')\n",
    "\n",
    "\n",
    "\n",
    "#model5.add(Activation(\"relu\"))\n",
    "#model5.add(Convolution2D(32, 3, 3,  border_mode='valid'))\n",
    "#model5.add(BatchNormalization())\n",
    "#model5.add(Activation(\"relu\"))\n",
    "#model5.add(BatchNormalization())\n",
    "#model5.add(Activation(\"relu\"))\n",
    "#model5.add(Dense(num_classes))\n",
    "#model5.add(BatchNormalization())\n",
    "#model5.add(Activation(\"softmax\"))\n",
    "# model5 the model\n",
    "# Train the model\n",
    "start = time.time()\n",
    "model5.fit(train_features, train_labels, batch_size=600, nb_epoch=3, verbose=2, validation_split=0.2)\n",
    "end = time.time()\n",
    "# plot model history\n",
    "#plot_model_history(model5_info)\n",
    "#print (\"Model took %0.2f seconds to train\"%(end - start))\n",
    "# compute test accuracy\n",
    "#print (\"Accuracy on test data is: %0.2f\"%accuracy(test_features, test_labels, model5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12132181295752525, 0.9641]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores=model5.evaluate(test_features,test_labels,verbose=0)\n",
    "acc_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
